The advent of natural language embeddings has created new tools for semantic interpretation of text. Semantic text embeddings use a generative language model to map a text passage into a high dimensional fixed-length vector. These mappings of unstructured text converts the task of assessing language meaning to assigning concepts to regions of a high-dimensional vector embedding space.

In this paper we explore using text embeddings for {\it semantic indexing} to improve the selection and interpretation of documents. The embedding vector space lacks interpretability, since its dimensions, despite their superiority  as classifier features, are unlabelled. We present several approaches to learning {\it concept vectors} in the embedding space that map regions to meanings. 

Conventional approaches to model interpretability apply once a model's predictions are made, in an attempt to ``explain'' the model in a specific context.  The problem with this approach is often that decisions were made in the design and application of the model without involving the client. Explanation becomes a post-hoc attempt to justify the applicability of the model's results. 

In our view the process of model interpretation commences before construction and training of a model, by eliciting a context from the human client. 
%Here's an example of how this can work: A person searching PubMed for various subjects related to animals would be misled by indiscriminately using the MeSH term ``animal'', since the term in the context of the indexed literature is biased toward mice and rats as test specimens. The connotation of the term has deviated from the technical definition of ``animal''. 
This is possible by transforming the embedding space with concept vectors, into a representation where the client can apply domain knowlege, separately and prior to document ranking and selection. Clustering and prediction among concept vectors captures domain specific biases as a way to 
% The client is a human who conveys both the intentions of the model and offers expertise in the domain to which it is applied. Examples in this paper concern a medical expert searching keyword-indexed bio-medical literature. The document search methods we are developing involve the client-expert in clarifying the meaning of search concepts, which allows for cutomization of the model query prior to running a document search.  Thus the client can be involved in ``co-construction,'' to borrow a term from the learning literature [], of the model.  Any model implicity includes domain biases, where the meaning of labels may have connotations colored by the domain, the imbalance of training classes, and the choice of model features. This is unavoidable, and arguably adds to domain specific value, if these biases can be made explicit. 
% To this end the  structured high-dimensional space of concept vectors is a rich representation to 
explore the meaning of terms used as training labels so they may be put in context with each other, and with the literature they represent. 


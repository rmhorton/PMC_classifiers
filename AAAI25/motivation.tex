\subsection{How Interpretability Fits Within Alignment}

The advent of natural language embeddings derived from large language models has created new tools for semantic interpretation of text. Semantic text embeddings use a generative language model to map a text passage into a high dimensional fixed-length vector. These mappings of unstructured text converts the task of assessing language meaning to assigning concepts to points in a high-dimensional vector space. However the embedding vector space lacks interpretability, since its dimensions, despite their superiority as classifier features, are unlabelled. We demonstrate how a a multi-label classifier trained on a keyword-labeled corpus can be used as a transform from the original {\em concept vector} embedding space to an equivalent labelled vector space.  

Attempts to interpret a model applied to a specific domain after predictions are made are hindered by assumptions uninformed by the context where the model will be used.   The problem with the conventional approach to interpretability is often that decisions were made initially in the design of the model that do not align with the domain context in which the model is applied. Explanation reduces to merely a post-hoc attempt to justify the applicability of the model's results. Preferably The model builder should involve users from the targeted domain, to reveal values implicit in how the model is applied, and in selection of relevant training data. The contextual information obtained from users is logically prior to the data and training of the model. 


In our view the process of model interpretation must incorporate domain considerations that affect construction and training of a model, by eliciting a context from persons who will use it. Interpretation is made possible by alignment of model construction with the larger domain context of the decisions and values to which it is applied. The emphasis in interpretation switches from just explicating how the model works, to how the model aligns with the decisions and values it is applied to.  A simple example illustrates this: A person searching the {\em PubMed} database for various publications related to animals would be misled by indiscriminately using the MeSH keyword term ``animal'', since the term in the context of the indexed literature is biased toward mice and rats as test specimens. The connotation of the term has deviated from the technical definition of ``animal''.  Given this, one can re-interpret keyword semantics in the context the term is used, e.g. ``animals'' to mean experimental test animals, or, critically address the selection of data used to train the model to match the search semantics around the term ``animal''.

In this paper we present a transformation of text embeddings to a related space of labelled features, to improve the selection and interpretation of documents. This is possible by transforming the concept vector space, into a representation where the client can apply domain knowledge that reveal semantic biases, separately and logically prior to document ranking and selection . 
The domain expert is a person who conveys both the intentions of the model and offers expertise in the domain to which it is applied. Examples in this paper concern a medical expert searching keyword-indexed bio-medical literature. The document search methods we are developing involve the client-expert in clarifying the meaning of search concepts, which allows for customization of the model query prior to running a document search.  Thus the client can be involved in ``co-construction,'' to borrow a term from the learning literature [], of the model.  Any model implicitly includes domain biases, where the meaning of labels may have connotations colored by the domain, the imbalance of training classes, and the choice of model features. This is unavoidable, and arguably adds to domain specific value, if these biases can be made explicit. 

To this end the transformation of the high-dimensional concept vector space via a multi-label classifier to a semantic representation  
makes it possible to contextualize the construction and use of text search with embedding vectors.  

